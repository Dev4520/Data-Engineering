This is a real time dataset of the ineuron technical consultant team. You have to perform hive analysis on this given dataset.

Download Dataset 1 - https://drive.google.com/file/d/1WrG-9qv6atP-W3P_-gYln1hHyFKRKMHP/view

Download Dataset 2 - https://drive.google.com/file/d/1-JIPCZ34dyN6k9CqJa-Y8yxIGq6vTVXU/view

Note: both files are csv files. 


Q1. Create a schema based on the given dataset
     # Data loaded to local with help of filezila
     -ls
     :- AgentLogingReport.csv  AgentPerformance.csv
      # csv dataset loaded to LFS to HDFS 
      - hadoop fs -put /home/cloudera/hivemini_porject/AgentLogingReport.csv /shekhar
      - hadoop fs -put /home/cloudera/hivemini_porject/AgentPerformance.csv /shekhar
      o/p:- /shekhar/AgentLogingReport.csv
            /shekhar/AgentPerformance.csv
               
     # Dataset-1
    - create table AgentLogReport
    (
    srno int,
    agent string,
    date string,
    login_time string,
    logout_time string,
    duration string
    )
    row format delimited
    fields terminated by ','
    tblproperties("skip.header.line.count"="1");
    # data loaded hadoop to hive table-
    - laod data inpath '/shekhar/AgentLogingReport.csv' into table agentlogreport;
    
    # see table detail-
    - describe formattd agentlogreport;
    location:- hdfs://quickstart.cloudera:8020/user/hive/warehouse/miniproject.db/agentlogreport
    
    # to see table schema detail-
    - select agentlogreport;
    o/p:- col_name	          data_type	comment
          srno                	int                 	                    
          agent               	string              	                    
          date                	string              	                    
          login_time          	string              	                    
          logout_time         	string              	                    
          duration            	string              	                    
          Time taken: 0.382 seconds, Fetched: 6 row(s)
    # To see table data detial-
    - select formatted agentlogreport limit 10;
    o/p:- agentlogreport.srno	agentlogreport.agent	agentlogreport.date	agentlogreport.login_time	agentlogreport.logout_time	agentlogreport.duration
               1	Shivananda Sonwane	22-07-30	15:35:29	17:39:39	2:04:10
               2	Khushboo Priya	22-07-30	15:06:59	15:07:16	0:00:17
               3	Nandani Gupta	22-07-30	15:04:24	17:31:07	2:26:42
               4	Hrisikesh Neogi	22-07-30	14:34:29	15:19:35	0:45:06
               5	Mukesh	22-07-30	14:03:15	15:11:52	1:08:36
               6	Sowmiya Sivakumar	22-07-30	14:03:11	15:05:37	1:02:26
               7	Manjunatha A	22-07-30	14:00:12	15:08:29	1:08:16
               8	Harikrishnan Shaji	22-07-30	13:53:05	16:06:49	2:13:43
               9	Suraj S Bilgi	22-07-30	13:50:01	15:11:42	1:21:41
               10	Shivan K	22-07-30	13:28:18	13:59:00	0:30:42
               Time taken: 0.093 seconds, Fetched: 10 row(s)
    
    # Dataset- 2
    - create table AgentPerformance
    (
    srno int,
    date string,
    agent_name string,
    total_chat int,
    avg_resp_time string,
    avg_reso_time string,
    avg_rating float,
    total_fb int
    )
    row format delimited
    fields terminated by ','
    tblproperties("skip.header.line.count"="1");

2. Dump the data inside the hdfs in the given schema location.
3. List of all agents' names. 
4. Find out agent average rating.
5. Total working days for each agents 
6. Total query that each agent have taken 
7. Total Feedback that each agent have received 
8. Agent name who have average rating between 3.5 to 4 
9. Agent name who have rating less than 3.5 
10. Agent name who have rating more than 4.5 
11. How many feedback agents have received more than 4.5 average
12. average weekly response time for each agent 
13. average weekly resolution time for each agents 
14. Find the number of chat on which they have received a feedback 
15. Total contribution hour for each and every agents weekly basis 
16. Perform inner join, left join and right join based on the agent column and after joining the table export that data into your local system.
17. Perform partitioning on top of the agent column and then on top of that perform bucketing for each partitioning.
